{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06383e8c-2ae9-4069-bdb8-3d61ac20087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import albumentations as A\n",
    "import torch\n",
    "from torch.utils import data as torch_data\n",
    "from torch import nn as torch_nn\n",
    "from torch.nn import functional as torch_functional\n",
    "import torchvision\n",
    "from sklearn import metrics as sk_metrics\n",
    "from sklearn import model_selection as sk_model_selection\n",
    "import neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2d77df-6356-4319-acff-456523611c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"seed\": 42,\n",
    "    \n",
    "    \"valid_size\": 0.3,\n",
    "    \"image_size\": (512, 512),\n",
    "    \n",
    "    \"train_batch_size\": 4,\n",
    "    \"valid_batch_size\": 1,\n",
    "    \"test_batch_size\": 1,\n",
    "    \n",
    "    \"model\": \"mobilenet_v2\",\n",
    "    \n",
    "    \"max_epochs\": 50,\n",
    "    \"model_save_path\": \"model-best.torch\",\n",
    "    \"patience_stop\": 3,\n",
    "    \n",
    "    \"optimizer\": \"adam\",\n",
    "    \"adam_lr\": 0.0001,\n",
    "    \n",
    "    \"criterion\": \"cross_entropy\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf06cf5-9277-4488-8cd0-1fdf9918060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The directory to the dataset\n",
    "BASE_DIR = '/Users/tejakolla/Documents/sem-2/Deep_learning/project-1-teja2002/archive'\n",
    "PATH_INDEX = os.path.join(BASE_DIR, \"index.csv\")\n",
    "PATH_TEST = os.path.join(BASE_DIR, \"test.csv\")\n",
    "PATH_METADATA = os.path.join(BASE_DIR, \"metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539d2336-daf2-4f52-8cee-49fd2a2e44de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read information about dataset\n",
    "df = pd.read_csv(PATH_INDEX)\n",
    "\n",
    "tmp_train, tmp_valid = sk_model_selection.train_test_split(\n",
    "    df, \n",
    "    test_size=config[\"valid_size\"], \n",
    "    random_state=config[\"seed\"], \n",
    "    stratify=df['class_id'],\n",
    ")\n",
    "\n",
    "\n",
    "def get_paths_and_targets(tmp_df):\n",
    "    # Get file paths\n",
    "    paths = tmp_df[\"path\"].values\n",
    "    # Create full paths (base dir + concrete file name)\n",
    "    paths = list(\n",
    "        map(\n",
    "            lambda x: os.path.join(BASE_DIR, x), \n",
    "            paths\n",
    "        )\n",
    "    )\n",
    "    # Get labels\n",
    "    targets = tmp_df[\"class_id\"].values\n",
    "    \n",
    "    return paths, targets\n",
    "\n",
    "\n",
    "# Get train file paths and targets\n",
    "train_paths, train_targets = get_paths_and_targets(tmp_train)\n",
    "\n",
    "# Get valid file paths and targets\n",
    "valid_paths, valid_targets = get_paths_and_targets(tmp_valid)\n",
    "\n",
    "df_test = pd.read_csv(PATH_TEST)\n",
    "# Get test file paths and targets\n",
    "test_paths, test_targets = get_paths_and_targets(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1ad13c-7891-442e-90b8-5b18d92cb229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of classes in the dataset (len of unique labels in data)\n",
    "df_metadata = pd.read_csv(PATH_METADATA, encoding='ISO-8859-1')\n",
    "n_classes = df_metadata.shape[0]\n",
    "print(\"Number of classes: \", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486586c7-c3e1-4fd3-8426-6f695dcce2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataRetriever(torch_data.Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        paths, \n",
    "        targets, \n",
    "        image_size,\n",
    "        transforms=None,\n",
    "        preprocess=None,\n",
    "    ):\n",
    "        self.paths = paths\n",
    "        self.targets = targets\n",
    "        self.image_size = image_size\n",
    "        self.transforms = transforms\n",
    "        self.preprocess = preprocess\n",
    "          \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = cv2.imread(self.paths[index])\n",
    "        img = cv2.resize(img, self.image_size)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)['image']\n",
    "        if self.preprocess:\n",
    "            img = self.preprocess(img)\n",
    "        \n",
    "        y = torch.tensor(self.targets[index] - 1, dtype=torch.long)\n",
    "            \n",
    "        return {'X': img, 'y': y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3435581c-02f1-48c7-bd8f-adcede008156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Rotate(limit=30, border_mode=cv2.BORDER_REPLICATE, p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "        ], \n",
    "        p=1.0\n",
    "    )\n",
    "\n",
    "def get_preprocess():\n",
    "    return torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            ),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1647aa2f-aecf-4383-b996-0a497cb71ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_retriever = DataRetriever(\n",
    "    train_paths, \n",
    "    train_targets, \n",
    "    image_size=config[\"image_size\"],\n",
    "    transforms=get_train_transforms(),\n",
    "    preprocess=get_preprocess(),\n",
    ")\n",
    "\n",
    "valid_data_retriever = DataRetriever(\n",
    "    valid_paths, \n",
    "    valid_targets, \n",
    "    image_size=config[\"image_size\"],\n",
    "    preprocess=get_preprocess(),\n",
    ")\n",
    "\n",
    "test_data_retriever = DataRetriever(\n",
    "    test_paths, \n",
    "    test_targets, \n",
    "    image_size=config[\"image_size\"],\n",
    "    preprocess=get_preprocess(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13088a8c-a246-4ae2-8d0c-cfa1cdb5fa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch_data.DataLoader(\n",
    "    train_data_retriever,\n",
    "    batch_size=config[\"train_batch_size\"],\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "valid_loader = torch_data.DataLoader(\n",
    "    valid_data_retriever, \n",
    "    batch_size=config[\"valid_batch_size\"],\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "test_loader = torch_data.DataLoader(\n",
    "    test_data_retriever, \n",
    "    batch_size=config[\"test_batch_size\"],\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c22d70-7f0d-416e-bc0d-c133f29975c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_image(image):\n",
    "    # Denormalize and ensure the values are clipped within the valid range\n",
    "    image = image * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]\n",
    "    return image.clip(0, 1)  # Clip values to the [0, 1] range\n",
    "\n",
    "# Let's visualize some batches of the train data\n",
    "fig = plt.figure(figsize=(16, 16))\n",
    "for i_batch, batch in enumerate(train_loader):\n",
    "    images, labels = batch[\"X\"], batch[\"y\"]\n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(4, 4, 4 * i_batch + i + 1)\n",
    "        plt.imshow(denormalize_image(images[i].permute(1, 2, 0).numpy()))\n",
    "        plt.title(labels[i].numpy())\n",
    "        plt.axis(\"off\")\n",
    "    if i_batch >= 3:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0b8a80-ecc4-4f11-b378-9355b3f7c845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize some batches of the train data\n",
    "fig = plt.figure(figsize=(16, 16))\n",
    "for i_batch, batch in enumerate(valid_loader):\n",
    "    images, labels = batch[\"X\"], batch[\"y\"]\n",
    "    plt.subplot(4, 4, i_batch + 1)\n",
    "    plt.imshow(denormalize_image(images[0].permute(1, 2, 0).numpy()))\n",
    "    plt.title(labels[0].numpy())\n",
    "    plt.axis(\"off\")\n",
    "    if i_batch >= 15:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73961cb1-ee01-4fa5-8da8-ea1db07e9a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_mobilenet_v2(n_classes):\n",
    "    net = torch.hub.load(\"pytorch/vision:v0.6.0\", \"mobilenet_v2\", pretrained=True)\n",
    "    net.classifier = torch_nn.Linear(\n",
    "        in_features=1280, \n",
    "        out_features=n_classes, \n",
    "        bias=True,\n",
    "    )\n",
    "    return net\n",
    "\n",
    "def init_model_resnet18(n_classes):\n",
    "    net = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)\n",
    "    net.classifier = torch_nn.Linear(\n",
    "        in_features=512, \n",
    "        out_features=n_classes, \n",
    "        bias=True,\n",
    "    )\n",
    "    return net\n",
    "\n",
    "def init_model_resnet101(n_classes):\n",
    "    net = torch.hub.load('pytorch/vision:v0.6.0', 'resnet101', pretrained=True)\n",
    "    net.classifier = torch_nn.Linear(\n",
    "        in_features=2048, \n",
    "        out_features=n_classes, \n",
    "        bias=True,\n",
    "    )\n",
    "    return net\n",
    "\n",
    "def init_model_vgg16(n_classes):\n",
    "    net = torch.hub.load('pytorch/vision:v0.6.0', 'vgg16', pretrained=True)\n",
    "    net.classifier[6] = torch_nn.Linear(\n",
    "        in_features=4096, \n",
    "        out_features=n_classes, \n",
    "        bias=True,\n",
    "    )\n",
    "    return net\n",
    "\n",
    "def init_model_resnext50_32x4d(n_classes):\n",
    "    net = torch.hub.load('pytorch/vision:v0.6.0', 'resnext50_32x4d', pretrained=True)\n",
    "    net.classifier = torch_nn.Linear(\n",
    "        in_features=2048, \n",
    "        out_features=n_classes, \n",
    "        bias=True,\n",
    "    )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0c8764-c7f8-46e7-bdbb-2c6a3479b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossMeter:\n",
    "    def __init__(self):\n",
    "        self.avg = 0\n",
    "        self.n = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        self.n += 1\n",
    "        # incremental update\n",
    "        self.avg = val / self.n + (self.n - 1) / self.n * self.avg\n",
    "\n",
    "        \n",
    "class AccMeter:\n",
    "    def __init__(self):\n",
    "        self.avg = 0\n",
    "        self.n = 0\n",
    "        \n",
    "    def update(self, y_true, y_pred):\n",
    "        y_true = y_true.cpu().numpy().astype(int)\n",
    "        y_pred = y_pred.cpu().numpy().argmax(axis=1).astype(int)\n",
    "        last_n = self.n\n",
    "        self.n += len(y_true)\n",
    "        true_count = np.sum(y_true == y_pred)\n",
    "        # incremental update\n",
    "        self.avg = true_count / self.n + last_n / self.n * self.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799805bb-8f41-4754-bfcb-e0477c7bcdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        model, \n",
    "        device, \n",
    "        optimizer, \n",
    "        criterion, \n",
    "        loss_meter, \n",
    "        score_meter\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.loss_meter = loss_meter\n",
    "        self.score_meter = score_meter\n",
    "        \n",
    "        self.best_valid_score = -np.inf\n",
    "        self.n_patience = 0\n",
    "        \n",
    "        self.messages = {\n",
    "            \"epoch\": \"[Epoch {}: {}] loss: {:.5f}, score: {:.5f}, time: {} s\",\n",
    "            \"checkpoint\": \"The score improved from {:.5f} to {:.5f}. Save model to '{}'\",\n",
    "            \"patience\": \"\\nValid score didn't improve last {} epochs.\"\n",
    "        }\n",
    "    \n",
    "    def fit(self, epochs, train_loader, valid_loader, save_path, patience):\n",
    "        history = {\n",
    "            \"train_loss\": [],\n",
    "            \"train_score\": [],\n",
    "            \"valid_loss\": [],\n",
    "            \"valid_score\": [],\n",
    "        }\n",
    "        \n",
    "        for n_epoch in range(1, epochs + 1):\n",
    "            self.info_message(\"EPOCH: {}\", n_epoch)\n",
    "            \n",
    "            train_loss, train_score, train_time = self.train_epoch(train_loader)\n",
    "            valid_loss, valid_score, valid_time = self.valid_epoch(valid_loader)\n",
    "            \n",
    "            history[\"train_loss\"].append(train_loss)\n",
    "            history[\"train_score\"].append(train_score)\n",
    "            history[\"valid_loss\"].append(valid_loss)\n",
    "            history[\"valid_score\"].append(valid_score)\n",
    "            \n",
    "            self.info_message(\n",
    "                self.messages[\"epoch\"], \"Train\", n_epoch, train_loss, train_score, train_time\n",
    "            )\n",
    "            \n",
    "            self.info_message(\n",
    "                self.messages[\"epoch\"], \"Valid\", n_epoch, valid_loss, valid_score, valid_time\n",
    "            )\n",
    "            \n",
    "            if self.best_valid_score < valid_score:\n",
    "                self.info_message(\n",
    "                    self.messages[\"checkpoint\"], self.best_valid_score, valid_score, save_path\n",
    "                )\n",
    "                self.best_valid_score = valid_score\n",
    "                self.save_model(n_epoch, save_path)\n",
    "                self.n_patience = 0\n",
    "            else:\n",
    "                self.n_patience += 1\n",
    "            \n",
    "            if self.n_patience >= patience:\n",
    "                self.info_message(self.messages[\"patience\"], patience)\n",
    "                break\n",
    "        \n",
    "        return history\n",
    "            \n",
    "    def train_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        t = time.time()\n",
    "        train_loss = self.loss_meter()\n",
    "        train_score = self.score_meter()\n",
    "        \n",
    "        for step, batch in enumerate(train_loader, 1):\n",
    "            images = batch[\"X\"].to(self.device)\n",
    "            targets = batch[\"y\"].to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(images)\n",
    "\n",
    "            loss = self.criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            train_loss.update(loss.detach().item())\n",
    "            train_score.update(targets, outputs.detach())\n",
    "\n",
    "            self.optimizer.step()\n",
    "        \n",
    "        return train_loss.avg, train_score.avg, int(time.time() - t)\n",
    "    \n",
    "    def valid_epoch(self, valid_loader):\n",
    "        self.model.eval()\n",
    "        t = time.time()\n",
    "        valid_loss = self.loss_meter()\n",
    "        valid_score = self.score_meter()\n",
    "\n",
    "        for step, batch in enumerate(valid_loader, 1):\n",
    "            with torch.no_grad():\n",
    "                images = batch[\"X\"].to(self.device)\n",
    "                targets = batch[\"y\"].to(self.device)\n",
    "\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "\n",
    "                valid_loss.update(loss.detach().item())\n",
    "                valid_score.update(targets, outputs)\n",
    "        \n",
    "        return valid_loss.avg, valid_score.avg, int(time.time() - t)\n",
    "    \n",
    "    def save_model(self, n_epoch, save_path):\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state_dict\": self.model.state_dict(),\n",
    "                \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                \"best_valid_score\": self.best_valid_score,\n",
    "                \"n_epoch\": n_epoch,\n",
    "            },\n",
    "            save_path,\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def info_message(message, *args, end=\"\\n\"):\n",
    "        print(message.format(*args), end=end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e548892f-f004-461f-aa88-784ba0cb789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if config[\"model\"] == \"mobilenet_v2\":\n",
    "    model = init_model_mobilenet_v2(n_classes)\n",
    "elif config[\"model\"] == \"resnet18\":\n",
    "    model = init_model_resnet18(n_classes)\n",
    "elif config[\"model\"] == \"resnet101\":\n",
    "    model = init_model_resnet101(n_classes)\n",
    "elif config[\"model\"] == \"vgg16\":\n",
    "    model = init_model_vgg16(n_classes)\n",
    "elif config[\"model\"] == \"resnext50_32x4d\":\n",
    "    model = init_model_resnext50_32x4d(n_classes)\n",
    "    \n",
    "model.to(device)\n",
    "\n",
    "if config[\"optimizer\"] == \"adam\":\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"adam_lr\"])\n",
    "\n",
    "if config[\"criterion\"] == \"cross_entropy\":\n",
    "    criterion = torch_functional.cross_entropy\n",
    "\n",
    "trainer = Trainer(\n",
    "    model, \n",
    "    device, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    LossMeter, \n",
    "    AccMeter\n",
    ")\n",
    "\n",
    "history = trainer.fit(\n",
    "    config[\"max_epochs\"], \n",
    "    train_loader, \n",
    "    valid_loader, \n",
    "    config[\"model_save_path\"], \n",
    "    config[\"patience_stop\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756bfe8b-c433-499a-bb8c-c12a89d0c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize train and valid loss \n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='train loss')\n",
    "plt.plot(history['valid_loss'], label='valid loss')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.xlabel(\"Epoch number\", fontsize=15)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylabel(\"Loss value\", fontsize=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.grid()\n",
    "\n",
    "# Visualize train and valid accyracy \n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_score'], label='train acc')\n",
    "plt.plot(history['valid_score'], label='valid acc')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.xlabel(\"Epoch number\", fontsize=15)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylabel(\"Accuracy score\", fontsize=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ecbe63-83e1-480e-8594-859ad25452b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "checkpoint = torch.load(config[\"model_save_path\"])\n",
    "\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "best_valid_score = checkpoint[\"best_valid_score\"]\n",
    "n_epoch = checkpoint[\"n_epoch\"]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "print(f\"Best model valid score: {best_valid_score} ({n_epoch} epoch)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af2d92a-4469-4711-b8cf-5bb8776d7eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model predictions and true labels\n",
    "y_pred = []\n",
    "y_test = []\n",
    "for batch in test_loader:\n",
    "    y_pred.extend(model(batch['X'].to(device)).argmax(axis=-1).cpu().numpy())\n",
    "    y_test.extend(batch['y'])\n",
    "\n",
    "# Calculate needed metrics\n",
    "test_accuracy = sk_metrics.accuracy_score(y_test, y_pred)\n",
    "test_f1_macro = sk_metrics.f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "print(f\"Accuracy score on test data:\\t{test_accuracy}\")\n",
    "print(f\"Macro F1 score on test data:\\t{test_f1_macro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab97633f-7825-44de-9704-118c715ca188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata to get classes people-friendly names\n",
    "labels = df_metadata['minifigure_name'].tolist()\n",
    "\n",
    "# Calculate confusion matrix\n",
    "confusion_matrix = sk_metrics.confusion_matrix(y_test, y_pred)\n",
    "# confusion_matrix = confusion_matrix / confusion_matrix.sum(axis=1)\n",
    "df_confusion_matrix = pd.DataFrame(confusion_matrix, index=labels, columns=labels)\n",
    "\n",
    "# Show confusion matrix\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "sn.heatmap(df_confusion_matrix, annot=True, cbar=False, cmap='Oranges', linewidths=1, linecolor='black')\n",
    "plt.xlabel('Predicted labels', fontsize=15)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.ylabel('True labels', fontsize=15)\n",
    "plt.yticks(fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183dd2aa-4fa6-4c01-90fe-407b7380ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_images = []\n",
    "error_label = []\n",
    "error_pred = []\n",
    "error_prob = []\n",
    "for batch in test_loader:\n",
    "    _X_test, _y_test = batch['X'], batch['y']\n",
    "    pred = torch.softmax(model(_X_test.to(device)), axis=-1).detach().cpu().numpy()\n",
    "    pred_class = pred.argmax(axis=-1)\n",
    "    if pred_class != _y_test.cpu().numpy():\n",
    "        error_images.extend(_X_test)\n",
    "        error_label.extend(_y_test)\n",
    "        error_pred.extend(pred_class)\n",
    "        error_prob.extend(pred.max(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01445464-a610-41cd-8871-ca994b33cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 16))\n",
    "for ind, image in enumerate(error_images):\n",
    "    plt.subplot(math.ceil(len(error_images) / int(len(error_images) ** 0.5)), int(len(error_images) ** 0.5), ind + 1)\n",
    "    plt.imshow(denormalize_image(image.permute(1, 2, 0).numpy()))\n",
    "    plt.title(f\"Predict: {labels[error_pred[ind]]} ({error_prob[ind]:.2f}) Real: {labels[error_label[ind]]}\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61462f86-7d8b-45a2-aaa3-a9955958779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified = np.where(np.array(y_pred) != np.array(y_test))[0]\n",
    "misclassified_counts = sk_metrics.confusion_matrix(y_test, y_pred).sum(axis=1) - np.diag(sk_metrics.confusion_matrix(y_test, y_pred))\n",
    "most_confused_classes = np.argsort(misclassified_counts)[-5:]\n",
    "print(\"Most confused classes:\", [labels[i] for i in most_confused_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95e4a74-12bb-41a3-b7eb-60cf3842499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "\n",
    "test_dataset = test_loader.dataset \n",
    "\n",
    "def get_predictions_and_confidence(model, dataloader, device):\n",
    "    model.eval()\n",
    "    y_pred, y_test, confidence_scores = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch_x = batch[\"X\"].to(device)\n",
    "            batch_y = batch[\"y\"].cpu().numpy()\n",
    "\n",
    "            outputs = model(batch_x)\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=-1)\n",
    "            \n",
    "            pred_classes = outputs.argmax(dim=-1).cpu().numpy()\n",
    "            pred_confidences = probs.max(dim=-1).values.cpu().numpy()\n",
    "            \n",
    "            y_pred.extend(pred_classes)\n",
    "            y_test.extend(batch_y)\n",
    "            confidence_scores.extend(pred_confidences)\n",
    "    \n",
    "    return np.array(y_pred), np.array(y_test), np.array(confidence_scores)\n",
    "\n",
    "# Get predictions, actual labels, and confidence scores\n",
    "y_pred, y_test, confidence_scores = get_predictions_and_confidence(model, test_loader, device)\n",
    "\n",
    "# Identify correct and misclassified indices\n",
    "correct_indices = np.where(y_pred == y_test)[0]\n",
    "incorrect_indices = np.where(y_pred != y_test)[0]\n",
    "\n",
    "# Function to plot images\n",
    "def plot_images(indices, title, num_images=10):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    for i, idx in enumerate(indices[:num_images]):\n",
    "        img = test_dataset[idx][\"X\"]  # Fetch image\n",
    "        true_label = labels[y_test[idx]]  # Get true label\n",
    "        pred_label = labels[y_pred[idx]]  # Get predicted label\n",
    "        confidence = confidence_scores[idx]  # Get confidence score\n",
    "\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.imshow(ToPILImage()(img))  # Convert tensor to image\n",
    "        plt.title(f\"Pred: {pred_label} ({confidence:.2f})\\nTrue: {true_label}\", fontsize=10, color=\"green\" if pred_label == true_label else \"red\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(title, fontsize=14, fontweight=\"bold\")\n",
    "    plt.show()\n",
    "\n",
    "# Plot correctly classified images\n",
    "plot_images(correct_indices, \"Correctly Classified Images\")\n",
    "\n",
    "# Plot misclassified images\n",
    "plot_images(incorrect_indices, \"Misclassified Images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f89f4f4-2758-40ec-ade1-c14b71935de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5d87e6-33a1-4104-bf51-d765f846804b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.utils as vutils\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "# Define Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz, ngf, nc):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.LeakyReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.LeakyReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.LeakyReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.LeakyReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# Define Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nc, ndf):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1)\n",
    "\n",
    "# Hyperparameters\n",
    "nz = 128  # Changed from 256 to 128 for stability\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "nc = 3\n",
    "batch_size = 64  # Ensured consistent batch size\n",
    "\n",
    "# Initialize models\n",
    "netG = Generator(nz, ngf, nc).to(device)\n",
    "netD = Discriminator(nc, ndf).to(device)\n",
    "\n",
    "# Loss and Optimizers\n",
    "criterion = nn.BCELoss()\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=0.00005, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "\n",
    "# Dataset Setup (Using your dataset structure)\n",
    "dataset_root = '/Users/tejakolla/Documents/sem-2/Deep_learning/project-1-teja2002/archive'\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize images to [-1, 1]\n",
    "])\n",
    "\n",
    "# Loading the dataset with subfolders as different categories\n",
    "dataset = datasets.ImageFolder(root=dataset_root, transform=transform)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training DCGAN\n",
    "num_epochs = 1000\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # Train Discriminator\n",
    "        netD.zero_grad()\n",
    "        real_images = data[0].to(device)\n",
    "        batch_size = real_images.size(0)\n",
    "        labels = torch.full((batch_size,), real_label - 0.1, dtype=torch.float, device=device)  # Added label smoothing\n",
    "        output = netD(real_images)\n",
    "        lossD_real = criterion(output, labels)\n",
    "        lossD_real.backward()\n",
    "\n",
    "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        fake_images = netG(noise)\n",
    "        labels.fill_(fake_label + 0.1)  # Added label smoothing for fake labels\n",
    "        output = netD(fake_images.detach())\n",
    "        lossD_fake = criterion(output, labels)\n",
    "        lossD_fake.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Train Generator\n",
    "        netG.zero_grad()\n",
    "        labels.fill_(real_label)\n",
    "        output = netD(fake_images)\n",
    "        lossG = criterion(output, labels)\n",
    "        lossG.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "    # Generate sample images every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            fake_images = netG(fixed_noise).detach().cpu()\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"Generated Images - Epoch {epoch+1}\")\n",
    "        plt.imshow(np.transpose(vutils.make_grid(fake_images, padding=2, normalize=True), (1, 2, 0)))\n",
    "        plt.show()\n",
    "\n",
    "print(\"Training Complete!\")\n",
    "\n",
    "# Generate Synthetic LEGO Minifigure Images\n",
    "def generate_synthetic_images(num_images):\n",
    "    noise = torch.randn(num_images, nz, 1, 1, device=device)\n",
    "    with torch.no_grad():\n",
    "        fake_images = netG(noise).detach().cpu()\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Synthetic LEGO Minifigures\")\n",
    "    plt.imshow(np.transpose(vutils.make_grid(fake_images, padding=2, normalize=True), (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Generate and display 16 synthetic images\n",
    "generate_synthetic_images(16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3cee29-e208-4a55-9c07-e3b87ae341a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.utils as vutils\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "\n",
    "# Define Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz, ngf, nc):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# Define Discriminator (Critic for WGAN)\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nc, ndf):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "        nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "        nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ndf * 2),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "        nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ndf * 4),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "        nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ndf * 8),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "        nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False)\n",
    "    )\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1)\n",
    "\n",
    "# Wasserstein Loss\n",
    "def wasserstein_loss(output, target):\n",
    "    return torch.mean(output * target)\n",
    "\n",
    "# Gradient Penalty Calculation\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    batch_size, c, h, w = real_samples.size()\n",
    "    epsilon = torch.rand(batch_size, 1, 1, 1).expand_as(real_samples).to(device)\n",
    "    interpolated = epsilon * real_samples + (1 - epsilon) * fake_samples\n",
    "    interpolated.requires_grad_(True)\n",
    "\n",
    "    prob_interpolated = D(interpolated)\n",
    "    gradients = torch.autograd.grad(outputs=prob_interpolated, inputs=interpolated,\n",
    "                                    grad_outputs=torch.ones_like(prob_interpolated).to(device),\n",
    "                                    create_graph=True, retain_graph=True)[0]\n",
    "    gradients = gradients.view(batch_size, -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "# Hyperparameters\n",
    "nz = 128  # Latent vector size\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "nc = 3  # Number of channels in the images\n",
    "batch_size = 64\n",
    "num_epochs = 2000\n",
    "\n",
    "# Initialize models\n",
    "netG = Generator(nz, ngf, nc).to(device)\n",
    "netD = Discriminator(nc, ndf).to(device)\n",
    "\n",
    "# Optimizers\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=0.00005, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=0.00002, betas=(0.5, 0.999))\n",
    "\n",
    "# DataLoader Setup\n",
    "dataset_root = '/Users/tejakolla/Documents/sem-2/Deep_learning/project-1-teja2002/archive'\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=dataset_root, transform=transform)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training Loop for WGAN-GP\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        real_images = data[0].to(device)\n",
    "        batch_size = real_images.size(0)\n",
    "\n",
    "        noise_std = 0.1  # Small Gaussian noise to stabilize training\n",
    "        real_images += torch.randn_like(real_images) * noise_std\n",
    "        fake_images += torch.randn_like(fake_images) * noise_std\n",
    "\n",
    "        # Train Critic (Discriminator)\n",
    "        netD.zero_grad()\n",
    "        real_labels = torch.ones(batch_size, 1, device=device)\n",
    "        fake_labels = -torch.ones(batch_size, 1, device=device)\n",
    "        \n",
    "        # Real images\n",
    "        output = netD(real_images)\n",
    "        lossD_real = wasserstein_loss(output, real_labels)\n",
    "        \n",
    "        # Fake images\n",
    "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        fake_images = netG(noise)\n",
    "        output = netD(fake_images.detach())  # Detach to avoid training the generator with the critic\n",
    "        lossD_fake = wasserstein_loss(output, fake_labels)\n",
    "        \n",
    "        # Compute gradient penalty\n",
    "        gradient_penalty = compute_gradient_penalty(netD, real_images, fake_images)\n",
    "        \n",
    "        # Total discriminator loss\n",
    "        lossD = lossD_real + lossD_fake + 10 * gradient_penalty\n",
    "        lossD.backward(retain_graph=True)  # Retain graph to use in the next backward pass\n",
    "        optimizerD.step()\n",
    "        \n",
    "        # Train Generator (only once every n_critic steps)\n",
    "        if i % 5 == 0:\n",
    "            netG.zero_grad()\n",
    "            output = netD(fake_images)  # Use the fresh fake_images\n",
    "            lossG = wasserstein_loss(output, real_labels)\n",
    "            lossG.backward()  # No need to retain graph here for generator's backward pass\n",
    "            optimizerG.step()\n",
    "\n",
    "\n",
    "    # Print and visualize results periodically\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - D Loss: {lossD.item()}, G Loss: {lossG.item()}\")\n",
    "        with torch.no_grad():\n",
    "            fake_images = netG(fixed_noise).detach().cpu()\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(np.transpose(vutils.make_grid(fake_images, padding=2, normalize=True), (1, 2, 0)))\n",
    "        plt.title(f\"Generated Images - Epoch {epoch+1}\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "print(\"Training Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819e1809-dc08-479a-9451-14be7d869b19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
